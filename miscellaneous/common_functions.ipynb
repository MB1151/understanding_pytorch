{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [torch.nn.Softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html#softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a vector of real numbers $z = (z_{1}, z_{2}, ..., z_{n})$, the softmax function calculates the probability \n",
    "$p_{i}$ of the $i_{th}$ class as follows: \n",
    "\n",
    "$p_{i} = \\frac{e^{z_{i}}}{\\sum_{j=1}^{n}e^{z_{j}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([2, 3, 4])\n",
      "t1: \n",
      " tensor([[[ 1.1281e-03,  5.2460e-01, -2.0523e+00,  5.4018e-01],\n",
      "         [-6.2819e-01, -7.6226e-01,  1.6928e-01,  6.9731e-02],\n",
      "         [-1.1660e+00, -9.2012e-01,  7.7639e-01, -1.2223e+00]],\n",
      "\n",
      "        [[ 2.5709e-01,  1.8134e+00,  9.5059e-01,  1.4146e-01],\n",
      "         [ 7.5287e-01, -5.3057e-01, -6.7884e-01,  1.0876e+00],\n",
      "         [-1.0602e+00,  1.5446e-01, -1.2389e+00, -7.4936e-01]]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.randn(size=(2, 3, 4))\n",
    "print(\"shape: \", t1.shape)\n",
    "print(\"t1: \\n\", t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type:  <class 'torch.nn.modules.activation.Softmax'>\n",
      "Softmax(dim=-1)\n"
     ]
    }
   ],
   "source": [
    "softmax_obj = nn.Softmax(dim=-1)\n",
    "print(\"type: \", type(softmax_obj))\n",
    "print(softmax_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([2, 3, 4])\n",
      "t2: \n",
      " tensor([[[0.2207, 0.3726, 0.0283, 0.3784],\n",
      "         [0.1638, 0.1433, 0.3637, 0.3292],\n",
      "         [0.0980, 0.1254, 0.6839, 0.0927]],\n",
      "\n",
      "        [[0.1158, 0.5492, 0.2318, 0.1032],\n",
      "         [0.3432, 0.0951, 0.0820, 0.4797],\n",
      "         [0.1522, 0.5128, 0.1273, 0.2077]]])\n"
     ]
    }
   ],
   "source": [
    "# Notice that the output of the softmax is always >= 1.\n",
    "t2 = softmax_obj(t1)\n",
    "print(\"shape: \", t2.shape)\n",
    "print(\"t2: \\n\", t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [torch.nn.LogSoftmax](https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html#logsoftmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "LogSoftmax is almost the same as Softmax. It just calculates the log of probabilities.\n",
    "\n",
    "$LogSoftmax(i) = log(p_{i})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([2, 3, 4])\n",
      "t3: \n",
      " tensor([[[ 1.0472, -0.2998, -0.5796, -0.1466],\n",
      "         [-0.6364,  0.0129, -1.3613,  1.4907],\n",
      "         [ 0.3979, -1.8782,  0.1394, -0.0354]],\n",
      "\n",
      "        [[ 0.9524, -0.0172,  0.1861,  0.3807],\n",
      "         [-1.2351,  0.1988, -0.0174, -1.4718],\n",
      "         [ 1.5263,  2.6209,  0.4102, -0.0599]]])\n"
     ]
    }
   ],
   "source": [
    "t3 = torch.randn(size=(2, 3, 4))\n",
    "print(\"shape: \", t3.shape)\n",
    "print(\"t3: \\n\", t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type:  <class 'torch.nn.modules.activation.LogSoftmax'>\n",
      "LogSoftmax(dim=-1)\n"
     ]
    }
   ],
   "source": [
    "log_softmax_obj = nn.LogSoftmax(dim=-1)\n",
    "print(\"type: \", type(log_softmax_obj))\n",
    "print(log_softmax_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([2, 3, 4])\n",
      "t4: \n",
      " tensor([[[-0.5651, -1.9121, -2.1919, -1.7589],\n",
      "         [-2.4672, -1.8179, -3.1921, -0.3401],\n",
      "         [-0.9256, -3.2016, -1.1841, -1.3588]],\n",
      "\n",
      "        [[-0.8790, -1.8486, -1.6453, -1.4507],\n",
      "         [-2.2369, -0.8029, -1.0192, -2.4735],\n",
      "         [-1.5086, -0.4140, -2.6247, -3.0948]]])\n"
     ]
    }
   ],
   "source": [
    "# log(x) < 0 if x <= 1. Hence all the entires in t4 are <= 0. \n",
    "t4 = log_softmax_obj(t3)\n",
    "print(\"shape: \", t4.shape)\n",
    "print(\"t4: \\n\", t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pytorch_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
