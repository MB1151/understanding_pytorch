{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook, you learn:\n",
    "#\n",
    "# 1) What does torch.cat do?\n",
    "# 2) What does torch.stack do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [torch.cat](https://pytorch.org/docs/stable/generated/torch.cat.html#torch.cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating along a dimension means joining multiple tensors end-to-end along \n",
    "# the specified dimension. It effectively increases the size of the specified \n",
    "# dimension by adding tensors to that dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) torch.Size([2, 3])\n",
      "tensor([[ 7,  8,  9],\n",
      "        [10, 11, 12]]) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(t1, t1.shape, \"\\n\")\n",
    "t2 = torch.tensor([[7, 8, 9], [10, 11, 12]])\n",
    "print(t2, t2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9],\n",
      "        [10, 11, 12]]) torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# Both t1 and t2 have shape (2, 3) meaning they have 2 rows and 3 columns.\n",
    "# Dimension 0 points in the direction of rows i.e., top to bottom in a matrix.\n",
    "# When concatenating along dimension 0, we are joining the tensors along the rows effectively \n",
    "# increasing the number of rows in the concatenated result.\n",
    "t3 = torch.cat(tensors=[t1, t2], dim=0)\n",
    "print(t3, t3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  7,  8,  9],\n",
      "        [ 4,  5,  6, 10, 11, 12]]) torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "# Both t1 and t2 have shape (2, 3) meaning they have 2 rows and 3 columns.\n",
    "# Dimension 1 points in the direction of columns i.e., left to right in a matrix.\n",
    "# When concatenating along dimension 1, we are joining the tensors along the columns effectively\n",
    "# increasing the number of columns in the concatenated result.\n",
    "t4 = torch.cat(tensors=[t1, t2], dim=1)\n",
    "print(t4, t4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]]) torch.Size([2, 2, 2]) \n",
      "\n",
      "tensor([[[ 9, 10],\n",
      "         [11, 12]],\n",
      "\n",
      "        [[13, 14],\n",
      "         [15, 16]]]) torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "t5 = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "print(t5, t5.shape, \"\\n\")\n",
    "t6 = torch.tensor([[[9, 10], [11, 12]], [[13, 14], [15, 16]]])\n",
    "print(t6, t6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2],\n",
      "         [ 3,  4]],\n",
      "\n",
      "        [[ 5,  6],\n",
      "         [ 7,  8]],\n",
      "\n",
      "        [[ 9, 10],\n",
      "         [11, 12]],\n",
      "\n",
      "        [[13, 14],\n",
      "         [15, 16]]]) torch.Size([4, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Lets now understand the concatenation operation by looking at tensors as containers.\n",
    "# As we traverse along dimension 0, we get tensors of shape (2, 2). We append these (2, 2) tensors\n",
    "# from 't6' to 't5' to obtain the concatenated result.\n",
    "# To elaborate, we get the tensors [[9, 10], [11, 12]] and [[13, 14], [15, 16]] as we traverse\n",
    "# along dimension 0 in 't6'. We append these tensors at the end of 't5' as we traverse along\n",
    "# dimension 0 in 't5'. So, we first have [[1, 2], [3, 4]] and [[5, 6], [7, 8]] followed by the\n",
    "# tensors from 't6' in concatenated result.\n",
    "t7 = torch.cat(tensors=[t5, t6], dim=0)\n",
    "print(t7, t7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2],\n",
      "         [ 3,  4],\n",
      "         [ 9, 10],\n",
      "         [11, 12]],\n",
      "\n",
      "        [[ 5,  6],\n",
      "         [ 7,  8],\n",
      "         [13, 14],\n",
      "         [15, 16]]]) torch.Size([2, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "# As we traverse along dimension 1, we get the tensors of shape (2,). We append these (2,) tensors from\n",
    "# 't6' to 't5' to obtain the concatenated result.\n",
    "# To elaborate, we get the tensors [9, 10], [11, 12], [13, 14], [15, 16] as we traverse along dimension 1\n",
    "# in 't6'. We append these tensors to the corresponding tensors in 't5' as we traverse along dimension 1\n",
    "# in 't5'. Note that we obtain [9, 10] and [11, 12] by traversing the first (2, 2) tensor in 't6'. So, \n",
    "# these tensors are appended to the first (2, 2) tensor ([[1, 2], [3, 4]]) in 't5'. Similarly, we obtain \n",
    "# [13, 14] and [15, 16] by traversing the second (2, 2) tensor in 't6'. So, these tensors are appended to \n",
    "# the second (2, 2) tensor ([[5, 6], [7, 8]]) in 't6' in the concatenated result.\n",
    "t8 = torch.cat(tensors=[t5, t6], dim=1)\n",
    "print(t8, t8.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  9, 10],\n",
      "         [ 3,  4, 11, 12]],\n",
      "\n",
      "        [[ 5,  6, 13, 14],\n",
      "         [ 7,  8, 15, 16]]]) torch.Size([2, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "# As we traverse along dimension 2, we get individual numbers. We append these numbers from 't6' to 't5'\n",
    "# to obtain the concatenated result.\n",
    "# To elaborate, we get the numbers 9, 10, 11, 12, 13, 14, 15, 16 as we traverse along dimension 2 in 't6'.\n",
    "# We append these numbers to the corresponding tensors to 't5' as we traverse along dimension 2 in 't5'.\n",
    "# Note that we obtain 9, 10 by traversiog the first (2,) tensor in 't6'. So, these numbers are appended\n",
    "# to the first (2,) tensor ([1, 2]) in 't5'. Similarly, with pairs {11, 12}; {13, 14}; {15, 16}. \n",
    "t9 = torch.cat(tensors=[t5, t6], dim=2)\n",
    "print(t9, t9.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1,  2],\n",
      "          [ 3,  4]],\n",
      "\n",
      "         [[ 5,  6],\n",
      "          [ 7,  8]]],\n",
      "\n",
      "\n",
      "        [[[ 9, 10],\n",
      "          [11, 12]],\n",
      "\n",
      "         [[13, 14],\n",
      "          [15, 16]]]]) torch.Size([2, 2, 2, 2]) \n",
      "\n",
      "tensor([[[[17, 18],\n",
      "          [19, 20]],\n",
      "\n",
      "         [[21, 22],\n",
      "          [23, 24]]],\n",
      "\n",
      "\n",
      "        [[[25, 26],\n",
      "          [27, 28]],\n",
      "\n",
      "         [[29, 30],\n",
      "          [31, 32]]]]) torch.Size([2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "t10 = torch.tensor([[[[1, 2], [3, 4]], [[5, 6], [7, 8]]], [[[9, 10], [11, 12]], [[13, 14], [15, 16]]]])\n",
    "print(t10, t10.shape, \"\\n\")\n",
    "t11 = torch.tensor([[[[17, 18], [19, 20]], [[21, 22], [23, 24]]], [[[25, 26], [27, 28]], [[29, 30], [31, 32]]]])\n",
    "print(t11, t11.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1,  2],\n",
      "          [ 3,  4]],\n",
      "\n",
      "         [[ 5,  6],\n",
      "          [ 7,  8]]],\n",
      "\n",
      "\n",
      "        [[[ 9, 10],\n",
      "          [11, 12]],\n",
      "\n",
      "         [[13, 14],\n",
      "          [15, 16]]],\n",
      "\n",
      "\n",
      "        [[[17, 18],\n",
      "          [19, 20]],\n",
      "\n",
      "         [[21, 22],\n",
      "          [23, 24]]],\n",
      "\n",
      "\n",
      "        [[[25, 26],\n",
      "          [27, 28]],\n",
      "\n",
      "         [[29, 30],\n",
      "          [31, 32]]]]) torch.Size([4, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Following the same logic as above, the 2 '3D' tensors from 't11' are appended along dimension 0\n",
    "# to the 2 '3D' tensors in 't10'\n",
    "t12 = torch.cat(tensors=[t10, t11], dim=0)\n",
    "print(t12, t12.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1,  2],\n",
      "          [ 3,  4]],\n",
      "\n",
      "         [[ 5,  6],\n",
      "          [ 7,  8]],\n",
      "\n",
      "         [[17, 18],\n",
      "          [19, 20]],\n",
      "\n",
      "         [[21, 22],\n",
      "          [23, 24]]],\n",
      "\n",
      "\n",
      "        [[[ 9, 10],\n",
      "          [11, 12]],\n",
      "\n",
      "         [[13, 14],\n",
      "          [15, 16]],\n",
      "\n",
      "         [[25, 26],\n",
      "          [27, 28]],\n",
      "\n",
      "         [[29, 30],\n",
      "          [31, 32]]]]) torch.Size([2, 4, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Following the same logic as above, the 4 '2D' tensors from 't11' are appended along dimension 1\n",
    "# to the corresponding '2D' tensors in 't10'.\n",
    "t13 = torch.cat(tensors=[t10, t11], dim=1)\n",
    "print(t13, t13.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1,  2],\n",
      "          [ 3,  4],\n",
      "          [17, 18],\n",
      "          [19, 20]],\n",
      "\n",
      "         [[ 5,  6],\n",
      "          [ 7,  8],\n",
      "          [21, 22],\n",
      "          [23, 24]]],\n",
      "\n",
      "\n",
      "        [[[ 9, 10],\n",
      "          [11, 12],\n",
      "          [25, 26],\n",
      "          [27, 28]],\n",
      "\n",
      "         [[13, 14],\n",
      "          [15, 16],\n",
      "          [29, 30],\n",
      "          [31, 32]]]]) torch.Size([2, 2, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "# Following the same logic as above, the 8 '1D' tensors from 't11' are appended along dimension 2\n",
    "# to the corresponding '1D' tensors in 't10'.\n",
    "t14 = torch.cat(tensors=[t10, t11], dim=2)\n",
    "print(t14, t14.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1,  2, 17, 18],\n",
      "          [ 3,  4, 19, 20]],\n",
      "\n",
      "         [[ 5,  6, 21, 22],\n",
      "          [ 7,  8, 23, 24]]],\n",
      "\n",
      "\n",
      "        [[[ 9, 10, 25, 26],\n",
      "          [11, 12, 27, 28]],\n",
      "\n",
      "         [[13, 14, 29, 30],\n",
      "          [15, 16, 31, 32]]]]) torch.Size([2, 2, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "# Following the same logic as above, the 16 numbers from 't11' are appended along dimension 3\n",
    "# to the corresponding numbers in 't10'.\n",
    "t15 = torch.cat(tensors=[t10, t11], dim=3)\n",
    "print(t15, t15.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [torch.stack](https://pytorch.org/docs/stable/generated/torch.stack.html#torch.stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This [video](https://www.youtube.com/watch?v=kF2AlpykJGY) presents a view where torch.stack operation\n",
    "# is a 'torch.unqueeze' operation followed by 'torch.cat'.\n",
    "#\n",
    "# Honestly, I didn't really understand intuitively what 'torch.stack' in cases other than when dim=0 is used. \n",
    "# The official documentation says that it concatenates the tensors along the new dimension which is not \n",
    "# clear to me. However, to understand how the stack operation manipulates the tensors, it can be viewed as \n",
    "# a combination of 'unsqueeze' and 'cat' i.e., We first unsqueeze (add a dimension) the tensor at given index\n",
    "# and then concatente the unsqueezed tensors along the given dimension.\n",
    "# \n",
    "# Please refer to 'understanding_simple_pytorch_tensor_manipulations_part_1.ipynb' notebook to understand\n",
    "# the unsqueeze operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) torch.Size([3]) \n",
      "\n",
      "tensor([4, 5, 6]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "t16 = torch.tensor([1, 2, 3])\n",
    "print(t16, t16.shape, \"\\n\")\n",
    "t17 = torch.tensor([4, 5, 6])\n",
    "print(t17, t17.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) torch.Size([2, 3]) \n",
      "\n",
      "t18 = t19\n"
     ]
    }
   ],
   "source": [
    "# Add a new dimension (at dim 0) and stack the tensors along this dimension.\n",
    "# So, [1, 2, 3] and [4, 5, 6] are stacked on top of one another to get a 2D tensor. \n",
    "t18 = torch.stack(tensors=[t16, t17], dim=0)\n",
    "print(t18, t18.shape, \"\\n\")\n",
    "\n",
    "t19 = torch.cat(tensors=[torch.unsqueeze(input=t16, dim=0), torch.unsqueeze(input=t17, dim=0)], dim=0)\n",
    "if torch.equal(t18, t19):\n",
    "    print(\"t18 = t19\")\n",
    "else:\n",
    "    print(\"t18 != t19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]]) torch.Size([3, 2]) \n",
      "\n",
      "t20 = t21\n"
     ]
    }
   ],
   "source": [
    "t20 = torch.stack(tensors=[t16, t17], dim=1)\n",
    "print(t20, t20.shape, \"\\n\")\n",
    "\n",
    "t21 = torch.cat(tensors=[torch.unsqueeze(input=t16, dim=1), torch.unsqueeze(input=t17, dim=1)], dim=1)\n",
    "if torch.equal(t20, t21):\n",
    "    print(\"t20 = t21\")\n",
    "else:\n",
    "    print(\"t20 != t21\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) torch.Size([2, 3]) \n",
      "\n",
      "tensor([[ 7,  8,  9],\n",
      "        [10, 11, 12]]) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "t22 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(t22, t22.shape, \"\\n\")\n",
    "\n",
    "t23 = torch.tensor([[7, 8, 9], [10, 11, 12]])\n",
    "print(t23, t23.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12]]]) torch.Size([2, 2, 3]) \n",
      "\n",
      "t24 = t25\n"
     ]
    }
   ],
   "source": [
    "t24 = torch.stack(tensors=[t22, t23], dim=0)\n",
    "print(t24, t24.shape, \"\\n\")\n",
    "\n",
    "t25 = torch.cat(tensors=[torch.unsqueeze(input=t22, dim=0), torch.unsqueeze(input=t23, dim=0)], dim=0)\n",
    "if torch.equal(t24, t25):\n",
    "    print(\"t24 = t25\")\n",
    "else:\n",
    "    print(\"t24 != t25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3],\n",
      "         [ 7,  8,  9]],\n",
      "\n",
      "        [[ 4,  5,  6],\n",
      "         [10, 11, 12]]]) torch.Size([2, 2, 3]) \n",
      "\n",
      "t26 = t27\n"
     ]
    }
   ],
   "source": [
    "t26 = torch.stack(tensors=[t22, t23], dim=1)\n",
    "print(t26, t26.shape, \"\\n\")\n",
    "\n",
    "t27 = torch.cat(tensors=[torch.unsqueeze(input=t22, dim=1), torch.unsqueeze(input=t23, dim=1)], dim=1)\n",
    "if torch.equal(t26, t27):\n",
    "    print(\"t26 = t27\")\n",
    "else:\n",
    "    print(\"t26 != t27\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  7],\n",
      "         [ 2,  8],\n",
      "         [ 3,  9]],\n",
      "\n",
      "        [[ 4, 10],\n",
      "         [ 5, 11],\n",
      "         [ 6, 12]]]) torch.Size([2, 3, 2]) \n",
      "\n",
      "t28 = t29\n"
     ]
    }
   ],
   "source": [
    "t28 = torch.stack(tensors=[t22, t23], dim=2)\n",
    "print(t28, t28.shape, \"\\n\")\n",
    "\n",
    "t29 = torch.cat(tensors=[torch.unsqueeze(input=t22, dim=2), torch.unsqueeze(input=t23, dim=2)], dim=2)\n",
    "if torch.equal(t28, t29):\n",
    "    print(\"t28 = t29\")\n",
    "else:\n",
    "    print(\"t28 != t29\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pytorch_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
