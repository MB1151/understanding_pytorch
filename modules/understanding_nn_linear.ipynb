{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook, you learn:\n",
    "# \n",
    "# 1) How to use nn.linear in pytorch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usefule Resources:\n",
    "# \n",
    "# 1) https://docs.kanaries.net/topics/Python/nn-linear\n",
    "#       -- Very good blog that explains what is 'nn.Linear' and how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=5, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# Applies a linear transformation on the incoming input.\n",
    "# output = input * Weight_{Transpose} + Bias\n",
    "#\n",
    "# For the example linear_layer below, the input should be a tensor of size 5 and the output is \n",
    "# a tensor of size 1. \n",
    "linear_layer = nn.Linear(in_features=5, out_features=1, bias=True)\n",
    "print(linear_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n",
      "tensor([1., 2., 3., 4., 5.])\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "torch.Size([1])\n",
      "tensor([0.1204], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# The linear_layer object (pytorch module) is itself callable and applies the linear transformation\n",
    "# on calling the object with an input.\n",
    "input1 = torch.tensor(data=[1, 2, 3, 4, 5], dtype=torch.float)\n",
    "print(input1.shape)\n",
    "print(input1)\n",
    "print(\"-\" * 150)\n",
    "output1 = linear_layer(input1)\n",
    "print(output1.shape)\n",
    "print(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1352,  0.1167,  0.0176,  0.1402, -0.0964]], requires_grad=True) torch.Size([1, 5])\n",
      "Parameter containing:\n",
      "tensor([-0.1091], requires_grad=True) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# The linear_layer has 2 sets of parameters (weight and bias) that are used in the linear transformation\n",
    "# calculation. \n",
    "# The weight parameter has the shape (out_features x in_features) = (1, 5)\n",
    "print(linear_layer.weight, linear_layer.weight.shape)\n",
    "print(linear_layer.bias, linear_layer.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, what happens if the input is not a 1D tensor? What if the input is a 2D tensor or \n",
    "# a 3D tensor or some other high dimensional tensor?\n",
    "#\n",
    "# Linear Layer always operates on the last dimension of the input layer. The input tensor\n",
    "# can have any shape with the condition that the size of the last dimension should be \n",
    "# equal to the number of input features expected by the linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5])\n",
      "tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.,  9., 10.]])\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "torch.Size([2, 1])\n",
      "tensor([[0.1204],\n",
      "        [0.3343]], grad_fn=<AddmmBackward0>)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "tensor([0.1204], grad_fn=<ViewBackward0>)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "tensor([0.3343], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input2 = torch.tensor(data=[[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]], dtype=torch.float)\n",
    "print(input2.shape)\n",
    "print(input2)\n",
    "print(\"-\" * 150)\n",
    "\n",
    "# input2 is 2D tensor containing two 1D tensors [1, 2, 3, 4, 5] and [6, 7, 8, 9, 10].\n",
    "# Linear transformation operates on the last dimension i.e., it independently transforms\n",
    "# the two 1D tensors.\n",
    "# \n",
    "# linear_layer([1, 2, 3, 4, 5])  --> -2.5216 --> Same as output3\n",
    "# linear_layer([6, 7, 8, 9, 10]) --> -6.1213 --> Same as output4\n",
    "# \n",
    "# Also, notice that the shape of the input is maintained in the output.\n",
    "output2 = linear_layer(input2)\n",
    "print(output2.shape)\n",
    "print(output2)\n",
    "print(\"-\" * 150)\n",
    "\n",
    "output3 = linear_layer(torch.tensor(data=[1, 2, 3, 4, 5], dtype=torch.float))\n",
    "print(output3)\n",
    "print(\"-\" * 150)\n",
    "\n",
    "output4 = linear_layer(torch.tensor(data=[6, 7, 8, 9, 10], dtype=torch.float))\n",
    "print(output4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 5])\n",
      "tensor([[[ 1.,  2.,  3.,  4.,  5.],\n",
      "         [ 6.,  7.,  8.,  9., 10.]],\n",
      "\n",
      "        [[11., 12., 13., 14., 15.],\n",
      "         [16., 17., 18., 19., 20.]]])\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "torch.Size([2, 2, 1])\n",
      "tensor([[[0.1204],\n",
      "         [0.3343]],\n",
      "\n",
      "        [[0.5483],\n",
      "         [0.7622]]], grad_fn=<ViewBackward0>)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "tensor([0.1204], grad_fn=<ViewBackward0>)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "tensor([0.3343], grad_fn=<ViewBackward0>)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "tensor([0.5483], grad_fn=<ViewBackward0>)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "tensor([0.7622], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input3 = torch.tensor(data=[[[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]], [[11, 12, 13, 14, 15], [16, 17, 18, 19, 20]]], dtype=torch.float)\n",
    "print(input3.shape)\n",
    "print(input3)\n",
    "print(\"-\" * 150)\n",
    "# input2 is 3D tensor containing four 1D tensors [1, 2, 3, 4, 5]; [6, 7, 8, 9, 10]; \n",
    "# [11, 12, 13, 14, 15] and [16, 17, 18, 19, 20]\n",
    "# Linear transformation operates on the last dimension i.e., it independently transforms\n",
    "# the four 1D tensors.\n",
    "# \n",
    "# linear_layer([1, 2, 3, 4, 5])      --> -2.5216  --> Same as output6\n",
    "# linear_layer([6, 7, 8, 9, 10])     --> -6.1213  --> Same as output7\n",
    "# linear_layer([11, 12, 13, 14, 15]) --> -9.7209  --> Same as output8\n",
    "# linear_layer([16, 17, 18, 19, 20]) --> -13.3206 --> Same as output9\n",
    "#\n",
    "# Also, notice that the shape of the input is maintained in the output.\n",
    "output5 = linear_layer(input3)\n",
    "print(output5.shape)\n",
    "print(output5)\n",
    "print(\"-\" * 150)\n",
    "\n",
    "output6 = linear_layer(torch.tensor(data=[1, 2, 3, 4, 5], dtype=torch.float))\n",
    "print(output6)\n",
    "print(\"-\" * 150)\n",
    "\n",
    "output7 = linear_layer(torch.tensor(data=[6, 7, 8, 9, 10], dtype=torch.float))\n",
    "print(output7)\n",
    "print(\"-\" * 150)\n",
    "\n",
    "output8 = linear_layer(torch.tensor(data=[11, 12, 13, 14, 15], dtype=torch.float))\n",
    "print(output8)\n",
    "print(\"-\" * 150)\n",
    "\n",
    "output9 = linear_layer(torch.tensor(data=[16, 17, 18, 19, 20], dtype=torch.float))\n",
    "print(output9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "torch.Size([2, 3])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x3 and 5x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(input4\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# As expected, this raises an error since the size of the last dimension (3) is different\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# from the number of input features expected by the linear_layer\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m output10 \u001b[38;5;241m=\u001b[39m \u001b[43mlinear_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput4\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Learning/AI/Frameworks/Pytorch/Understanding_Pytorch/.pytorch_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Learning/AI/Frameworks/Pytorch/Understanding_Pytorch/.pytorch_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Learning/AI/Frameworks/Pytorch/Understanding_Pytorch/.pytorch_venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x3 and 5x1)"
     ]
    }
   ],
   "source": [
    "input4 = torch.tensor(data=[[1, 2, 3], [4, 5, 6]], dtype=torch.float)\n",
    "print(input4)\n",
    "print(input4.shape)\n",
    "\n",
    "# As expected, this raises an error since the size of the last dimension (3) is different\n",
    "# from the number of input features expected by the linear_layer\n",
    "output10 = linear_layer(input4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pytorch_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
